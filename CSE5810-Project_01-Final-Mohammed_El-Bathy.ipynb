{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a42409cf-e0f9-4c88-aecd-f816020d8090",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score, GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from statsmodels.tools.tools import add_constant\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn import tree\n",
    "\n",
    "# Global variables\n",
    "data = None\n",
    "encoded_data = None\n",
    "X_resampled = None\n",
    "y_resampled = None\n",
    "dt_model = None\n",
    "lr_model = None\n",
    "rf_model = None\n",
    "lr_results = None\n",
    "rf_results = None\n",
    "\n",
    "# Function 1: Import Libraries\n",
    "def import_libraries():\n",
    "    return \"Libraries imported successfully.\"\n",
    "\n",
    "# Function 2: Load the Dataset\n",
    "def load_dataset():\n",
    "    global data\n",
    "    file_path = 'default_of_credit_card_clients.csv'\n",
    "    data = pd.read_csv(file_path, header=1)\n",
    "    return data\n",
    "\n",
    "# Function 3: Display statistical summary\n",
    "def display_statistics():\n",
    "    global data\n",
    "    if data is not None:\n",
    "        return data.describe().T\n",
    "    else:\n",
    "        return \"Data not loaded.\"\n",
    "\n",
    "# Function 4: Display correlation matrix\n",
    "def display_correlation():\n",
    "    global data\n",
    "    if data is not None:\n",
    "        fig, ax = plt.subplots(figsize=(10, 6))\n",
    "        correlation_matrix = data.corr()\n",
    "        sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f', ax=ax)\n",
    "        ax.set_title('Correlation Matrix of Features')\n",
    "        \n",
    "        buf = BytesIO()\n",
    "        fig.savefig(buf, format=\"png\")\n",
    "        buf.seek(0)\n",
    "        plt.close(fig)  \n",
    "        return Image.open(buf)\n",
    "    else:\n",
    "        return \"Data not loaded.\"\n",
    "\n",
    "# Function 5: Outlier Detection and Handling\n",
    "def outlier_detection():\n",
    "    global data\n",
    "    if data is not None:\n",
    "        numeric_columns = ['LIMIT_BAL', 'AGE', 'BILL_AMT1', 'BILL_AMT2', 'BILL_AMT3', \n",
    "                           'BILL_AMT4', 'BILL_AMT5', 'BILL_AMT6', 'PAY_AMT1', \n",
    "                           'PAY_AMT2', 'PAY_AMT3', 'PAY_AMT4', 'PAY_AMT5', 'PAY_AMT6']\n",
    "        for column in numeric_columns:\n",
    "            upper_limit = data[column].quantile(0.99)\n",
    "            lower_limit = data[column].quantile(0.01)\n",
    "            data[column] = np.clip(data[column], lower_limit, upper_limit)\n",
    "        return \"Outliers capped at 1st and 99th percentiles.\"\n",
    "    else:\n",
    "        return \"Data not loaded.\"\n",
    "\n",
    "# Function 6: Encoding Categorical Variables\n",
    "def encoding_categorical():\n",
    "    global data, encoded_data\n",
    "    if data is not None:\n",
    "        encoded_data = pd.get_dummies(data, columns=['SEX', 'EDUCATION', 'MARRIAGE'], \n",
    "                                      drop_first=True)\n",
    "        return encoded_data\n",
    "    else:\n",
    "        return \"Data not loaded.\"\n",
    "\n",
    "# Function 7: Feature Scaling\n",
    "def feature_scaling():\n",
    "    global encoded_data\n",
    "    if encoded_data is not None:\n",
    "        continuous_columns = ['LIMIT_BAL', 'AGE', 'PAY_AMT1', 'PAY_AMT2', 'PAY_AMT3', \n",
    "                              'PAY_AMT4', 'PAY_AMT5', 'PAY_AMT6']\n",
    "        scaler = StandardScaler()\n",
    "        encoded_data[continuous_columns] = scaler.fit_transform(encoded_data[continuous_columns])\n",
    "        return encoded_data\n",
    "    else:\n",
    "        return \"Encoded data not available.\"\n",
    "\n",
    "# Function 8: Apply SMOTE\n",
    "def apply_smote():\n",
    "    global encoded_data, X_resampled, y_resampled\n",
    "    if encoded_data is not None:\n",
    "        X = encoded_data.drop(columns=['default payment next month'])\n",
    "        y = encoded_data['default payment next month']\n",
    "        smote = SMOTE(random_state=42)\n",
    "        X_resampled, y_resampled = smote.fit_resample(X, y)\n",
    "        return f\"SMOTE applied: Resampled dataset shape: {X_resampled.shape}\"\n",
    "    else:\n",
    "        return \"Encoded data not available.\"\n",
    "\n",
    "# Function 9: Calculate VIF\n",
    "def calculate_vif():\n",
    "    global encoded_data\n",
    "    if encoded_data is not None:\n",
    "        numeric_data = encoded_data.select_dtypes(include=[np.number])\n",
    "        X_vif = add_constant(numeric_data)\n",
    "        vif_data = pd.DataFrame()\n",
    "        vif_data[\"Feature\"] = X_vif.columns\n",
    "        vif_data[\"VIF\"] = [variance_inflation_factor(X_vif.values, i) for i in range(X_vif.shape[1])]\n",
    "        return vif_data\n",
    "    else:\n",
    "        return \"Encoded data not available.\"\n",
    "\n",
    "# Function 12: Recalculate VIF\n",
    "def recalculate_vif():\n",
    "    global encoded_data\n",
    "    if encoded_data is not None:\n",
    "        numeric_data = encoded_data.select_dtypes(include=[np.number])\n",
    "        X_vif_updated = add_constant(numeric_data)\n",
    "        vif_data_updated = pd.DataFrame()\n",
    "        vif_data_updated[\"Feature\"] = X_vif_updated.columns\n",
    "        vif_data_updated[\"VIF\"] = [variance_inflation_factor(X_vif_updated.values, i) for i in range(X_vif_updated.shape[1])]\n",
    "        return vif_data_updated\n",
    "    else:\n",
    "        return \"Encoded data not available.\"\n",
    "\n",
    "# Function 13: Visualize Distribution\n",
    "def visualize_distribution():\n",
    "    global data, encoded_data\n",
    "    if data is not None and encoded_data is not None:\n",
    "        fig, axes = plt.subplots(2, 3, figsize=(10, 6))\n",
    "        sns.histplot(data['LIMIT_BAL'], bins=30, kde=True, ax=axes[0, 0]).set_title('Distribution of Credit Limit')\n",
    "        sns.histplot(data['AGE'], bins=30, kde=True, ax=axes[0, 1]).set_title('Distribution of Age')\n",
    "        sns.countplot(x='SEX_2', data=encoded_data, ax=axes[0, 2]).set_title('Distribution of Gender')\n",
    "        sns.countplot(x='EDUCATION_2', data=encoded_data, ax=axes[1, 0]).set_title('Distribution of Education')\n",
    "        sns.countplot(x='MARRIAGE_1', data=encoded_data, ax=axes[1, 1]).set_title('Distribution of Marital Status')\n",
    "        sns.countplot(x='default payment next month', data=data, ax=axes[1, 2]).set_title('Default vs Non-default')\n",
    "        plt.tight_layout()\n",
    "        \n",
    "        buf = BytesIO()\n",
    "        fig.savefig(buf, format=\"png\")\n",
    "        buf.seek(0)\n",
    "        plt.close(fig)\n",
    "        return Image.open(buf)\n",
    "    else:\n",
    "        return \"Data not loaded.\"\n",
    "\n",
    "# Function 14: Initialize and Train Decision Tree\n",
    "def initialize_decision_tree():\n",
    "    global dt_model, X_resampled, y_resampled\n",
    "    if X_resampled is not None and y_resampled is not None:\n",
    "        dt_model = DecisionTreeClassifier(random_state=42)\n",
    "        dt_model.fit(X_resampled, y_resampled)\n",
    "        return \"Decision Tree Classifier initialized and trained.\"\n",
    "    else:\n",
    "        return \"SMOTE resampled data not available.\"\n",
    "\n",
    "# Function 15: K-Fold Cross-Validation for Decision Tree\n",
    "def cross_validation_decision_tree():\n",
    "    global dt_model, X_resampled, y_resampled\n",
    "    if dt_model is not None and X_resampled is not None:\n",
    "        kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "        accuracy_scores = cross_val_score(dt_model, X_resampled, y_resampled, cv=kf, scoring='accuracy')\n",
    "        roc_auc_scores = cross_val_score(dt_model, X_resampled, y_resampled, cv=kf, scoring='roc_auc')\n",
    "        return f\"Mean Accuracy: {accuracy_scores.mean():.4f}, Std Dev: {accuracy_scores.std():.4f}\\n\" \\\n",
    "               f\"Mean ROC-AUC: {roc_auc_scores.mean():.4f}, Std Dev: {roc_auc_scores.std():.4f}\"\n",
    "    else:\n",
    "        return \"Decision Tree or resampled data not available.\"\n",
    "\n",
    "# Function 16: Visualize Decision Tree Structure\n",
    "def visualize_decision_tree():\n",
    "    global dt_model, X_resampled\n",
    "    if dt_model is not None and X_resampled is not None:\n",
    "        plt.figure(figsize=(20, 10))\n",
    "        tree.plot_tree(dt_model, feature_names=X_resampled.columns, class_names=['No Default', 'Default'], filled=True)\n",
    "        buf = BytesIO()\n",
    "        plt.savefig(buf, format=\"png\")\n",
    "        buf.seek(0)\n",
    "        plt.close()\n",
    "        return Image.open(buf)\n",
    "    else:\n",
    "        return \"Decision Tree model not trained.\"\n",
    "\n",
    "# Function 17: Confusion Matrix Visualization for Decision Tree\n",
    "def visualize_confusion_matrix_decision_tree():\n",
    "    global dt_model, X_resampled, y_resampled\n",
    "    if dt_model is not None and X_resampled is not None:\n",
    "        plt.figure(figsize=(4, 4))\n",
    "        sns.heatmap(confusion_matrix(y_resampled, dt_model.predict(X_resampled)), annot=True, fmt='d', cmap='Blues')\n",
    "        buf = BytesIO()\n",
    "        plt.savefig(buf, format=\"png\")\n",
    "        buf.seek(0)\n",
    "        plt.close()\n",
    "        return Image.open(buf)\n",
    "    else:\n",
    "        return \"Decision Tree or resampled data not available.\"\n",
    "\n",
    "# Function 18: Classification Report for Decision Tree\n",
    "def classification_report_dt():\n",
    "    global dt_model, X_resampled, y_resampled\n",
    "    if dt_model is not None and X_resampled is not None:\n",
    "        y_pred = dt_model.predict(X_resampled)\n",
    "        report = classification_report(y_resampled, y_pred)\n",
    "        return report\n",
    "    else:\n",
    "        return \"Decision Tree or resampled data not available.\"\n",
    "\n",
    "# Function 19: Initialize and Train Logistic Regression\n",
    "def initialize_logistic_regression():\n",
    "    global lr_model, X_resampled, y_resampled\n",
    "    if X_resampled is not None and y_resampled is not None:\n",
    "        lr_model = LogisticRegression(max_iter=1000, random_state=42)\n",
    "        lr_model.fit(X_resampled, y_resampled)\n",
    "        return \"Logistic Regression model initialized and trained.\"\n",
    "    else:\n",
    "        return \"SMOTE resampled data not available.\"\n",
    "\n",
    "# Function 20: Logistic Regression Evaluation\n",
    "def evaluate_logistic_regression():\n",
    "    global lr_model, X_resampled, y_resampled\n",
    "    if lr_model is not None and X_resampled is not None:\n",
    "        y_pred = lr_model.predict(X_resampled)\n",
    "        report = classification_report(y_resampled, y_pred)\n",
    "        auc = roc_auc_score(y_resampled, lr_model.predict_proba(X_resampled)[:, 1])\n",
    "        return f\"Classification Report:\\n{report}\\nROC-AUC Score: {auc:.4f}\"\n",
    "    else:\n",
    "        return \"Logistic Regression model or resampled data not available.\"\n",
    "\n",
    "# Function 21: Initialize and Train Random Forest with Hyperparameter Tuning\n",
    "def initialize_random_forest():\n",
    "    global rf_model, X_resampled, y_resampled, rf_results\n",
    "    if X_resampled is not None and y_resampled is not None:\n",
    "        rf_model = RandomForestClassifier(random_state=42)\n",
    "        param_grid = {\n",
    "            'n_estimators': [50, 100, 200],\n",
    "            'max_depth': [None, 10, 20, 30],\n",
    "            'min_samples_split': [2, 5, 10]\n",
    "        }\n",
    "        grid_search = GridSearchCV(rf_model, param_grid, cv=3, scoring='roc_auc', n_jobs=-1)\n",
    "        grid_search.fit(X_resampled, y_resampled)\n",
    "        \n",
    "        rf_model = grid_search.best_estimator_\n",
    "        rf_results = {\n",
    "            \"Best Parameters\": grid_search.best_params_,\n",
    "            \"Best ROC-AUC\": grid_search.best_score_\n",
    "        }\n",
    "        return f\"Random Forest model initialized and trained with tuning. Best ROC-AUC: {rf_results['Best ROC-AUC']:.4f}\"\n",
    "    else:\n",
    "        return \"SMOTE resampled data not available.\"\n",
    "\n",
    "# Function 22: Random Forest Evaluation\n",
    "def evaluate_random_forest():\n",
    "    global rf_model, X_resampled, y_resampled\n",
    "    if rf_model is not None and X_resampled is not None:\n",
    "        y_pred = rf_model.predict(X_resampled)\n",
    "        report = classification_report(y_resampled, y_pred)\n",
    "        auc = roc_auc_score(y_resampled, rf_model.predict_proba(X_resampled)[:, 1])\n",
    "        return f\"Classification Report:\\n{report}\\nROC-AUC Score: {auc:.4f}\"\n",
    "    else:\n",
    "        return \"Random Forest model or resampled data not available.\"\n",
    "\n",
    "# Gradio Interface Setup\n",
    "with gr.Blocks() as credit_default_interface:\n",
    "    with gr.Tab(\"Import Libraries\"):\n",
    "        gr.Interface(fn=import_libraries, inputs=[], outputs=\"text\").render()\n",
    "    with gr.Tab(\"Load Dataset\"):\n",
    "        gr.Interface(fn=load_dataset, inputs=[], outputs=\"dataframe\").render()\n",
    "    with gr.Tab(\"Display Statistics\"):\n",
    "        gr.Interface(fn=display_statistics, inputs=[], outputs=\"dataframe\").render()\n",
    "    with gr.Tab(\"Display Correlation\"):\n",
    "        gr.Interface(fn=display_correlation, inputs=[], outputs=gr.Image(type=\"pil\")).render()\n",
    "    with gr.Tab(\"Outlier Detection\"):\n",
    "        gr.Interface(fn=outlier_detection, inputs=[], outputs=\"text\").render()\n",
    "    with gr.Tab(\"Encoding Categorical Variables\"):\n",
    "        gr.Interface(fn=encoding_categorical, inputs=[], outputs=\"dataframe\").render()\n",
    "    with gr.Tab(\"Feature Scaling\"):\n",
    "        gr.Interface(fn=feature_scaling, inputs=[], outputs=\"dataframe\").render()\n",
    "    with gr.Tab(\"Apply SMOTE\"):\n",
    "        gr.Interface(fn=apply_smote, inputs=[], outputs=\"text\").render()\n",
    "    with gr.Tab(\"Calculate VIF\"):\n",
    "        gr.Interface(fn=calculate_vif, inputs=[], outputs=\"dataframe\").render()\n",
    "    with gr.Tab(\"Recalculate VIF\"):\n",
    "        gr.Interface(fn=recalculate_vif, inputs=[], outputs=\"dataframe\").render()\n",
    "    with gr.Tab(\"Visualize Distribution\"):\n",
    "        gr.Interface(fn=visualize_distribution, inputs=[], outputs=gr.Image(type=\"pil\")).render()\n",
    "    with gr.Tab(\"Initialize and Train Decision Tree\"):\n",
    "        gr.Interface(fn=initialize_decision_tree, inputs=[], outputs=\"text\").render()\n",
    "    with gr.Tab(\"Decision Tree Cross-Validation\"):\n",
    "        gr.Interface(fn=cross_validation_decision_tree, inputs=[], outputs=\"text\").render()\n",
    "    with gr.Tab(\"Visualize Decision Tree\"):\n",
    "        gr.Interface(fn=visualize_decision_tree, inputs=[], outputs=gr.Image(type=\"pil\")).render()\n",
    "    with gr.Tab(\"Decision Tree Confusion Matrix\"):\n",
    "        gr.Interface(fn=visualize_confusion_matrix_decision_tree, inputs=[], outputs=gr.Image(type=\"pil\")).render()\n",
    "    with gr.Tab(\"Decision Tree Classification Report\"):\n",
    "        gr.Interface(fn=classification_report_dt, inputs=[], outputs=\"text\").render()\n",
    "    with gr.Tab(\"Initialize and Train Logistic Regression\"):\n",
    "        gr.Interface(fn=initialize_logistic_regression, inputs=[], outputs=\"text\").render()\n",
    "    with gr.Tab(\"Evaluate Logistic Regression\"):\n",
    "        gr.Interface(fn=evaluate_logistic_regression, inputs=[], outputs=\"text\").render()\n",
    "    with gr.Tab(\"Initialize and Train Random Forest\"):\n",
    "        gr.Interface(fn=initialize_random_forest, inputs=[], outputs=\"text\").render()\n",
    "    with gr.Tab(\"Evaluate Random Forest\"):\n",
    "        gr.Interface(fn=evaluate_random_forest, inputs=[], outputs=\"text\").render()\n",
    "\n",
    "# Launch Interface\n",
    "credit_default_interface.launch(share=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "300aa829-08d7-4867-bb15-963e0181ffb5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
